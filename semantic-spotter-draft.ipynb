{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":6454164,"sourceType":"datasetVersion","datasetId":3726549}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# install required packages\n\n! pip install -qU langchain-community\n! pip install -qU langchain_huggingface\n! pip install -qU sentence-transformers\n! pip install -qU langchain-perplexity\n! pip install -qU faiss-cpu\n! pip install -qU gradio\n! pip install -qU kaggle","metadata":{"id":"5d9c81a9","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:47:08.570369Z","iopub.execute_input":"2025-10-01T11:47:08.570632Z","iopub.status.idle":"2025-10-01T11:49:20.152435Z","shell.execute_reply.started":"2025-10-01T11:47:08.570604Z","shell.execute_reply":"2025-10-01T11:49:20.151245Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Filter warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:49:20.154852Z","iopub.execute_input":"2025-10-01T11:49:20.155163Z","iopub.status.idle":"2025-10-01T11:49:20.160087Z","shell.execute_reply.started":"2025-10-01T11:49:20.155136Z","shell.execute_reply":"2025-10-01T11:49:20.159237Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# import libraries\n\nimport os, glob\nfrom pathlib import Path\nfrom langchain_community.document_loaders import PyMuPDFLoader, CSVLoader, TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom sentence_transformers import CrossEncoder, util\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_perplexity import ChatPerplexity\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.retrievers.document_compressors import CrossEncoderReranker\nfrom langchain_community.cross_encoders import HuggingFaceCrossEncoder\nfrom langchain_core.messages import HumanMessage, AIMessage\nimport gradio as gr\nfrom PIL import Image","metadata":{"id":"c604d8a9","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:49:20.160979Z","iopub.execute_input":"2025-10-01T11:49:20.161211Z","iopub.status.idle":"2025-10-01T11:50:09.254395Z","shell.execute_reply.started":"2025-10-01T11:49:20.161193Z","shell.execute_reply":"2025-10-01T11:50:09.253589Z"}},"outputs":[{"name":"stderr","text":"2025-10-01 11:49:44.235080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759319384.560972      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759319384.652262      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Set LLM keys from secret manager / local environment\n\nif os.path.exists('/kaggle'):\n    platform = 'Kaggle'\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    print(f\"Using kaggle secrets to get keys\")\n    os.environ['PERPLEXITY_API_KEY']  = user_secrets.get_secret(\"PPLX_API_KEY_2\")   \nelif os.path.exists('/content'):\n    platform = 'Colab'\n    from google.colab import userdata\n    print(f\"Using Google colab secrets to get keys\")\n    os.environ['PERPLEXITY_API_KEY'] = userdata.get('PPLX_API_KEY_2')\nelse:\n    platform = 'Local'\n    import dotenv\n    dotenv.load_dotenv()\n    print(f\"Using local env secrets to get keys\")\n    os.environ['PERPLEXITY_API_KEY'] = os.getenv('PPLX_API_KEY')    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.255256Z","iopub.execute_input":"2025-10-01T11:50:09.255877Z","iopub.status.idle":"2025-10-01T11:50:09.381972Z","shell.execute_reply.started":"2025-10-01T11:50:09.255854Z","shell.execute_reply":"2025-10-01T11:50:09.381112Z"}},"outputs":[{"name":"stdout","text":"Using kaggle secrets to get keys\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Define a base configuration\n\nconfig = {\n    'data_path' : '/kaggle/input/myntra-fashion-product-dataset/',\n    'images_path' : '/kaggle/input/myntra-fashion-product-dataset/images/',\n    'chunk_size' : 512,\n    'chunk_overlap' : 80,\n    'vector_store_name' : \"faiss_myntra_db\",\n    'embedding_model' : 'all-MiniLM-L6-v2',\n    'refresh_vector_store' : 'N',\n    'PPLX_API_KEY' : os.getenv('PERPLEXITY_API_KEY'),\n    'domain' : 'fashion',\n    'chat_model' : \"sonar-pro\",\n    'rerank_model' : 'BAAI/bge-reranker-base',\n    'platform' : platform\n}","metadata":{"id":"9e6ea496","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.382789Z","iopub.execute_input":"2025-10-01T11:50:09.383027Z","iopub.status.idle":"2025-10-01T11:50:09.387612Z","shell.execute_reply.started":"2025-10-01T11:50:09.383007Z","shell.execute_reply":"2025-10-01T11:50:09.386767Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Download dataset if not running on kaggle notebook\n\nif config['platform'] != 'Kaggle':\n    # Download dataset from kaggle using kaggle API\n    from kaggle.api.kaggle_api_extended import KaggleApi\n    \n    api = KaggleApi()\n    api.authenticate()\n    # api.dataset_download_files('promptcloud/myntra-e-commerce-product-data-november-2023', path='./data/', unzip=True)\n    # api.dataset_download_files(\"ronakbokaria/myntra-products-dataset\", path='./data/', unzip=True)\n    api.dataset_download_files(\"djagatiya/myntra-fashion-product-dataset\", path='./data/', unzip=True)","metadata":{"id":"ca535a39","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.389615Z","iopub.execute_input":"2025-10-01T11:50:09.389872Z","iopub.status.idle":"2025-10-01T11:50:09.408714Z","shell.execute_reply.started":"2025-10-01T11:50:09.389853Z","shell.execute_reply":"2025-10-01T11:50:09.408090Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define a function that will enhance the metadata of the documents\n\ndef add_metadata_to_documents(documents):\n    \"\"\"\n    Adds image URL and other attributes from page content to the metadata of each document.\n    \"\"\"\n    for doc in documents:\n        try:\n            image_url = doc.page_content.split(\"\\n\")[6].split(' ')[1]\n            doc.metadata['image_url'] = image_url\n            pid = doc.page_content.split('\\n')[0].split()[1]\n            doc.metadata['image_path_local'] = config['images_path'] + pid + \".jpg\"\n            doc.metadata['p_id'] = pid\n            doc.metadata['product_name'] = doc.page_content.split(\"\\n\")[1].split(' ')[1]\n            doc.metadata['product_category'] = doc.page_content.split(\"\\n\")[2].split(' ')[1]\n            doc.metadata['price'] = doc.page_content.split(\"\\n\")[3].split(' ')[1]\n            doc.metadata['color'] = doc.page_content.split(\"\\n\")[4].split(' ')[1]\n            doc.metadata['brand'] = doc.page_content.split(\"\\n\")[5].split(' ')[1]\n            doc.metadata['rating_count'] = doc.page_content.split(\"\\n\")[7].split(' ')[1]\n            doc.metadata['avg_rating'] = doc.page_content.split(\"\\n\")[8].split(' ')[1]\n        except (IndexError, AttributeError):\n            # Handle cases where the image URL might not be present or in a different format\n            doc.metadata['image_url'] = None\n            doc.metadata['image_path_local'] = None\n            doc.metadata['p_id'] = None\n            doc.metadata['product_name'] = None\n            doc.metadata['product_category'] = None\n            doc.metadata['price'] = None\n            doc.metadata['price'] = None\n            doc.metadata['brand'] = None\n            doc.metadata['rating_count'] = None\n            doc.metadata['avg_rating'] = None\n    return documents","metadata":{"id":"26c37152","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.409461Z","iopub.execute_input":"2025-10-01T11:50:09.409727Z","iopub.status.idle":"2025-10-01T11:50:09.427539Z","shell.execute_reply.started":"2025-10-01T11:50:09.409707Z","shell.execute_reply":"2025-10-01T11:50:09.426895Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def get_data_chunks(folder_path):\n  \"\"\"\n  This function will create chunks from the files present in the dataset.\n  This takes directory where the files exists. Basis the type of file i.e.\n  PDF, CSV or text, a loader is initialised and chunks are created from\n  content of the data\n  \"\"\"\n  # loader = PyMuPDFLoader(pdf_file)\n  # documents = loader.load()\n\n  all_documents = []\n\n  # Loop through all files in the folder\n  for file_path in folder_path.iterdir():\n      if file_path.suffix.lower() == \".pdf\":\n          loader = PyMuPDFLoader(str(file_path))\n      elif file_path.suffix.lower() == \".csv\":\n          loader = CSVLoader(str(file_path))\n      elif file_path.suffix.lower() == \".txt\":\n          loader = TextLoader(str(file_path))\n      else:\n          continue  # Skip unsupported file types\n\n      # Load and append documents\n      documents = loader.load()\n      documents_with_metadata = add_metadata_to_documents(documents)\n      all_documents.extend(documents_with_metadata)\n\n  # chunking/splitting\n  text_splitter = RecursiveCharacterTextSplitter(\n      chunk_size=config['chunk_size'],\n      chunk_overlap=config['chunk_overlap'],\n      strip_whitespace=True,\n      separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n  )\n  text_chunks = text_splitter.split_documents(documents=documents_with_metadata)\n  return text_chunks","metadata":{"id":"f67bc650","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.428336Z","iopub.execute_input":"2025-10-01T11:50:09.428598Z","iopub.status.idle":"2025-10-01T11:50:09.449132Z","shell.execute_reply.started":"2025-10-01T11:50:09.428579Z","shell.execute_reply":"2025-10-01T11:50:09.448242Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_embeddings_model():\n  embedding_model = HuggingFaceEmbeddings(\n      model_name=config['embedding_model'],\n      show_progress=True,\n      multi_process=True,\n      model_kwargs={'device': 'cuda'}\n  )\n  return embedding_model","metadata":{"id":"808bad53","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.449988Z","iopub.execute_input":"2025-10-01T11:50:09.450223Z","iopub.status.idle":"2025-10-01T11:50:09.473426Z","shell.execute_reply.started":"2025-10-01T11:50:09.450206Z","shell.execute_reply":"2025-10-01T11:50:09.472780Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def create_vector_store(text_chunks, embedding_model):\n  if config['refresh_vector_store'] == 'Y' or not os.path.exists(config['vector_store_name']):\n      vector_store = FAISS.from_documents(text_chunks, embedding_model)\n      vector_store.save_local(config['vector_store_name'])\n  else:\n      vector_store = FAISS.load_local(config['vector_store_name'], embedding_model, allow_dangerous_deserialization=True)\n  return vector_store","metadata":{"id":"290f41a6","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.474344Z","iopub.execute_input":"2025-10-01T11:50:09.474631Z","iopub.status.idle":"2025-10-01T11:50:09.490299Z","shell.execute_reply.started":"2025-10-01T11:50:09.474604Z","shell.execute_reply":"2025-10-01T11:50:09.489557Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def create_chat_client():\n  return ChatPerplexity(\n      temperature=0,\n      pplx_api_key=config['PPLX_API_KEY'], # Pass the API key explicitly\n      model=config['chat_model']\n  )","metadata":{"id":"2ebb800e","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.491115Z","iopub.execute_input":"2025-10-01T11:50:09.491354Z","iopub.status.idle":"2025-10-01T11:50:09.506225Z","shell.execute_reply.started":"2025-10-01T11:50:09.491330Z","shell.execute_reply":"2025-10-01T11:50:09.505578Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def get_retriever(top_k=10):\n  retriever = vector_store.as_retriever(search_kwargs={'k': top_k})\n  return retriever","metadata":{"id":"afbe7c02","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.507371Z","iopub.execute_input":"2025-10-01T11:50:09.507642Z","iopub.status.idle":"2025-10-01T11:50:09.527419Z","shell.execute_reply.started":"2025-10-01T11:50:09.507618Z","shell.execute_reply":"2025-10-01T11:50:09.526836Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def get_reranked_query_results(query):\n    model = HuggingFaceCrossEncoder(model_name=config['rerank_model'])\n    compressor = CrossEncoderReranker(model=model, top_n=3)\n    compression_retriever = ContextualCompressionRetriever(\n      base_compressor=compressor,\n      base_retriever=get_retriever()\n    )\n    compressed_docs = compression_retriever.invoke(query)\n    print(\"=\"*80)\n    print(f\"{compressed_docs}\")\n    print(\"=\"*80)\n    \n    return compressed_docs","metadata":{"id":"762f2797","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.528180Z","iopub.execute_input":"2025-10-01T11:50:09.528403Z","iopub.status.idle":"2025-10-01T11:50:09.544298Z","shell.execute_reply.started":"2025-10-01T11:50:09.528387Z","shell.execute_reply":"2025-10-01T11:50:09.543717Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def generate_llm_response(query, results):\n    llm = create_chat_client()\n    #if system_message is None:\n    system_message = f\"\"\" \n    You are a helpful AI assistant in fashion domain and expert in looking into given documents and find relevant products. \n    Do not give any product listing outside this context.\n    Context is give here:\n    #####\n    {results}\n    #####\n    If you don't know the answer, say so. Keep the conversation flowing.\n    \n    #####\n    You extract brand, price, avg_rating, rating_count, image_url and image_path_local from the metadata\n    #####\n    \"\"\"        \n    prompt_template = ChatPromptTemplate.from_messages([\n        (\"system\", \"{system_message}\"),\n        (\"human\", \"{query}\")\n    ])\n    \n    chain = prompt_template | llm\n    llm_response = chain.invoke(\n        {\"query\" : query,\n        \"system_message\" : system_message}\n    )\n    return llm_response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.544978Z","iopub.execute_input":"2025-10-01T11:50:09.545187Z","iopub.status.idle":"2025-10-01T11:50:09.560940Z","shell.execute_reply.started":"2025-10-01T11:50:09.545172Z","shell.execute_reply":"2025-10-01T11:50:09.560354Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def rag_pipeline(user_input):\n    # Get reranked top results of the user query\n    retrieved_documents = get_reranked_query_results(user_input)\n    # formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_documents)\n    formatted_context = \"\\n\\n\".join( (str(doc.metadata) + doc.page_content) for doc in retrieved_documents)\n    print(\"*\"*80)\n    print(f\"\\n\\n\\n {formatted_context} \\n\\n\\n\")\n    print(\"*\"*80)\n    answer = generate_llm_response(user_input, formatted_context)\n    return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.561619Z","iopub.execute_input":"2025-10-01T11:50:09.561875Z","iopub.status.idle":"2025-10-01T11:50:09.577229Z","shell.execute_reply.started":"2025-10-01T11:50:09.561859Z","shell.execute_reply":"2025-10-01T11:50:09.576645Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def get_answer(question):\n    # Call the RAG pipeline to get the answer based on the user's question.\n    final_answer = rag_pipeline(question)\n    return final_answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.577904Z","iopub.execute_input":"2025-10-01T11:50:09.578119Z","iopub.status.idle":"2025-10-01T11:50:09.598190Z","shell.execute_reply.started":"2025-10-01T11:50:09.578103Z","shell.execute_reply":"2025-10-01T11:50:09.597628Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Start the process and set path for dataset\n\nchunked_data = []\n\nif (config['platform']).lower() == 'kaggle':\n    folder_path = Path(\"/kaggle/input/myntra-fashion-product-dataset\")\nelif (config['platform']).lower() == 'colab':\n    folder_path = Path(\"/content/data/\")\nelse:\n    folder_path = Path(config['data_path'])\n\nprint(folder_path)","metadata":{"id":"d9b98630","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.598811Z","iopub.execute_input":"2025-10-01T11:50:09.599015Z","iopub.status.idle":"2025-10-01T11:50:09.615419Z","shell.execute_reply.started":"2025-10-01T11:50:09.599001Z","shell.execute_reply":"2025-10-01T11:50:09.614842Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/myntra-fashion-product-dataset\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"if config['refresh_vector_store'] == 'Y':\n    # Generate chunks from the dataset\n    chunked_data = get_data_chunks(folder_path)\n\n    # Create embeddings and put them into a vector store\n    embedding_model = get_embeddings_model()\n    vector_store = create_vector_store(chunked_data, embedding_model)\nelse:\n    vector_store = FAISS.load_local(\n        config['vector_store_name'],\n        get_embeddings_model(),\n        allow_dangerous_deserialization=True\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:09.618152Z","iopub.execute_input":"2025-10-01T11:50:09.618622Z","iopub.status.idle":"2025-10-01T11:50:18.729995Z","shell.execute_reply.started":"2025-10-01T11:50:09.618605Z","shell.execute_reply":"2025-10-01T11:50:18.729074Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb90728fa0a44f62bb26627784903b05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf8f90326fc64bdfa828cc97c9d417f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4553400118473a959aacfff545d545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ebc34fc5ae4da8b8abb39f8d4a826a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a578ec1efe43af9da6f1f6fe8e6bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e250a1f6fb4d1181af70886aa15d36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"322a22f36f804426bb1f67fb7ec3ff5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f9c81faf6854843b4c3c820084f8f5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f2d3d1e61a478ea0feec057e75b558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"494242dd3bc44245b47911b12790cea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0200642997d34999bad8093e6a570b1a"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"user_input = \"party dresses for women\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:50:18.730942Z","iopub.execute_input":"2025-10-01T11:50:18.731190Z","iopub.status.idle":"2025-10-01T11:50:18.735597Z","shell.execute_reply.started":"2025-10-01T11:50:18.731171Z","shell.execute_reply":"2025-10-01T11:50:18.734854Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import html\n\ndef gradio_chat_interface(user_input):\n    results = get_reranked_query_results(user_input)\n    response = generate_llm_response(user_input, results)\n    \n    # Clean HTML entities\n    cleaned_text = html.unescape(response.content.replace('\"', '\"').replace('&', '&'))\n    \n    # Get product images\n    images = []\n    for doc in results[:3]:\n        image_path = doc.metadata.get('image_path_local')\n        if image_path and os.path.exists(image_path):\n            try:\n                images.append(Image.open(image_path))\n            except:\n                images.append(None)\n        else:\n            images.append(None)\n    \n    while len(images) < 3:\n        images.append(None)\n    \n    return cleaned_text, images[0], images[1], images[2]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:03:17.742193Z","iopub.execute_input":"2025-10-01T12:03:17.742899Z","iopub.status.idle":"2025-10-01T12:03:17.748697Z","shell.execute_reply.started":"2025-10-01T12:03:17.742863Z","shell.execute_reply":"2025-10-01T12:03:17.747833Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Create Gradio interface\nwith gr.Blocks(title=\"Semantic Spotter\") as demo:\n    gr.Markdown(\"# ğŸ›ï¸ Semantic Spotter - Fashion Search\")\n    \n    with gr.Row():\n        user_input = gr.Textbox(label=\"Search Query\", placeholder=\"party dresses for women\", scale=3)\n        submit_btn = gr.Button(\"Search\", variant=\"primary\", scale=1)\n    \n    response_text = gr.Textbox(label=\"Recommendations\", lines=6, interactive=False)\n    \n    with gr.Row():\n        img1 = gr.Image(label=\"Product 1\", height=200)\n        img2 = gr.Image(label=\"Product 2\", height=200) \n        img3 = gr.Image(label=\"Product 3\", height=200)\n    \n    submit_btn.click(gradio_chat_interface, [user_input], [response_text, img1, img2, img3])\n    user_input.submit(gradio_chat_interface, [user_input], [response_text, img1, img2, img3])\n\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:03:26.170869Z","iopub.execute_input":"2025-10-01T12:03:26.171474Z","iopub.status.idle":"2025-10-01T12:03:27.887099Z","shell.execute_reply.started":"2025-10-01T12:03:26.171448Z","shell.execute_reply":"2025-10-01T12:03:27.886480Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://eb0b3a2a4989e4e809.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://eb0b3a2a4989e4e809.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}